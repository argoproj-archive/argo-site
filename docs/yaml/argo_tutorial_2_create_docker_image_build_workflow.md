# Tutorial 2: Build Docker Image and Deploy Workflow

This tutorial shows how to easily build and deploy docker images on Kubernetes.

In an Argo workflow, every step must be defined as a container specification and creates a Kubernetes job.

In some cases, you may need to run a Docker container from within a Docker container. For example, your Continuous Integration (CI) app (like Jenkins) may be containerized and you want to provide a build/test container for each CI job you want Jenkins to run. Or you may want to build a Docker container image from inside your containerized CI job. Docker is a very useful tool for running other tools.

To build a Docker container image within our Docker container step, <span class="GeneralApplatix Platform Name">Argo</span> uses the Docker-in-Docker (DinD) technique. If you are interested in knowing more about how DinD works, please see our blog on [https://applatix.com/case-docker-docker-kubernetes-part/](https://applatix.com/case-docker-docker-kubernetes-part/)

<Picture of DinD workflow >

## Run a Docker Build and Deploy (DinD) workflow

1.  Go to the sample `DinD` workflow repository at [https://github.com/argoproj](https://github.com/argoproj).
2.  Review the `dind-workflow.yaml` file under `.argo` folder in that repo. It has a checkout, build, approval and deploy step. Every step in the workflow needs to be defined as a container specification and creates a Kubernetes job. The `dind-workflow.yaml` workflow checks out code, builds a node.js image, pushes the image to Docker hub and then deploys it as a kubernetes deployment. For more details on the workflow and container YAML DSL please check the YAML tutorial at [Container and Workflow Templates](#/docs;doc=container_workflow_templates.md).

3.  Review the `dind-workflow.yaml` file under `.argo` folder in that repo. It has a checkout, build, approval and deploy step. This workflow checks out code, builds a node.js image, pushes the image to Docker hub and then deploys it as a Kubernetes deployment.

    To make the credentials secure for accessing the container registry, the YAML DSL example uses Argo Secret management to encrypt the user id and password.

    To build the Docker container within the Docker container, the YAML DSL code uses two Docker client commands to build this container: `docker build` and `docker push`.[Calvin] Edit the text below.

    [[where:

    *   `image: get.applatix.io/applatix/axscm:v1` indicates that the image is stored in the the Applatix Docker registry (which is a private registry) rather than the default Docker Hub registry.

        This container image contains various source control tools such as git and provides a generic wrapper command for checking out code no matter what source control system you are using

    *   `repo` and `commit` are two input parameters that tell the container where to get the source code. The `default` statement indicates that the input parameters are optional, and if not specified, the values are filled in using the current session, which is generated by the Applatix Console or the Applatix Policy Manager that automatically runs jobs in response to a commit or push event.
    *   `artifact` is a set of files that the container template generates. The set of files is named `code`. The artifact is created by collecting all the files that were checked out and stored in the `/src` directory.
    *   `resources` is an optional keyword that specifies how much memory and cpu that <span class="GeneralApplatix Platform Name">Argo</span> reserves for running the container.

        By default, <span class="GeneralApplatix Platform Name">Argo</span> allocates 1000MiB (1GiB) and 1 CPU core for each container.

        The memory reservation (`mem_mib`) is also a hard limit. If your container exceeds the reservation, it will be terminated.

        The cpu reservation (`cpu_cores`) is not a hard limit but is used primarily for packing containers onto Kubernetes nodes and for share-based cpu allocation.

    **TIP**: The default values are fine for most applications but you may want to override the defaults if your container can benefit from significantly more resources or if your container runs often and you want to reduce the cost of running the container.]]

4.  Since your Argo installation is automatically integrated with [https://github.com/argoproj](https://github.com/argoproj) repo, you can view it in your Argo dashboard under Catalog menu item along with other samples.
5.  Select <span class="UI_element">DinD</span> in the Catalog item and click <span class="UI_element">Run</span> to start the DinD build and deploy workflow.
6.  This workflow has a approval step which needs an email address as a mandatory input parameter called REQUIRED_APPROVALS. Enter an email id and click submit
7.  You will see the workflow running in <span class="GeneralApplatix Cluster Console">Argo Web UI</span> where every step is a container. You can check the log and artifact generated by clicking on each step.
8.  Once the workflow completes you will see a "<span class="UI_element">Sampleapp</span>" application deployed under <span class="UI_element">Applications</span> tab in <span class="GeneralApplatix Cluster Console">Argo Web UI</span>.
9.  Since your Argo installation is automatically integrated with [https://github.com/argoproj](https://github.com/argoproj) repo, you can view it in your Argo dashboard under Catalog menu item along with other samples
10.  Select <span class="UI_element">DinD</span> in the Catalog item and click <span class="UI_element">Run</span> to start the DinD build and deploy workflow.
11.  This workflow has a approval step which needs an email address as a mandatory input parameter called REQUIRED_APPROVALS. Enter an email id and click submit
12.  You will see the workflow running in <span class="GeneralApplatix Cluster Console">Argo Web UI</span> where every step is a container. You can check the log and artifact generated by clicking on each step.
13.  Once the workflow completes you will see a "<span class="UI_element">Sampleapp</span>" application deployed under <span class="UI_element">Applications</span> tab in <span class="GeneralApplatix Cluster Console">Argo Web UI</span>.

## Create and Run your custom Docker build and deploy workflow

### Create your YAML files

1.  Create a .argo folder under your repository
2.  Copy yamls from https://github.com/argoproj/dind/ to your .argo folder.
3.  axscm_checkout.yaml defines a container provided by Argo for checking out code in your aws s3 which can be accessed by your other workflow steps. You shouldn't need to modify it
4.  axapproval.yaml defines a container provided by Argo for sending email for approval. You shouldn't need to modify it
5.  Customize the dind-workflow.yaml with your build and deploy containers
6.  dind-project.yaml defines how it will show up in your Catalog menu. This is optional only if you want it to show up in your catalog. Otherwise you can run it against your commits in Timelines menu. You can also see and run all your yamls under Templates menu.
7.  If you want to add more test steps or setup a policy to automatically trigger this workflow then please review the steps and YAML under CI-workflow tutorial

### Manually RUN Your Workflow

1.  Since your Argo installation is integrated with your repo, you will see your commits in <span class="GeneralApplatix Cluster Console">Argo Web UI</span> under <span class="UI_element">Timeline</span> menu item
2.  You can select any commit, click on "Create a new job". Select the workflow name, enter input parameter value and click on submit

### Automatically TRIGGER Your Workflow

1.  To setup a policy to automatically trigger this workflow then please review the steps for policy creation and YAML under CI-workflow tutorial
2.  In Argo web UI, go to Templates menu and search for that policy and click enabled
3.  For every commit on that repo, based on your policy your workflow will get triggered